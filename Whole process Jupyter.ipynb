{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import en_core_web_md\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV,LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "data = pd.read_csv(\"reddit_worldnews_start_to_2016-11-22.csv\", encoding='latin-1')\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.216517e+09</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1.243837e+09</td>\n",
       "      <td>25.697511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.278120e+09</td>\n",
       "      <td>38.427444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>1.308658e+09</td>\n",
       "      <td>53.979581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1.342873e+09</td>\n",
       "      <td>92.048355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1.373529e+09</td>\n",
       "      <td>91.272569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1.404038e+09</td>\n",
       "      <td>119.458372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.436001e+09</td>\n",
       "      <td>161.502077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1.465642e+09</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_created    up_votes  down_votes   over_18\n",
       "year                                                \n",
       "2008  1.216517e+09   15.823906         0.0  0.000267\n",
       "2009  1.243837e+09   25.697511         0.0  0.000438\n",
       "2010  1.278120e+09   38.427444         0.0  0.000257\n",
       "2011  1.308658e+09   53.979581         0.0  0.001543\n",
       "2012  1.342873e+09   92.048355         0.0  0.000516\n",
       "2013  1.373529e+09   91.272569         0.0  0.000918\n",
       "2014  1.404038e+09  119.458372         0.0  0.000456\n",
       "2015  1.436001e+09  161.502077         0.0  0.000528\n",
       "2016  1.465642e+09  182.005654         0.0  0.000513"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column to contain 'year'\n",
    "data['year']='2008'\n",
    "for i in data.index:\n",
    "    data.at[i,'year'] = data.at[i,'date_created'][:4]\n",
    "data.groupby(['year']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see that the number of up_votes were rising through time. The reason for this is that Internet and Reddit were becoming more and more popular during this period (2008-2016). To eliminate the influence of time, we add \"popular\" label based on whether the up votes are in the top 5 percentile in every year's posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp is a dict that contains the 95% cutoff of each year\n",
    "temp={}\n",
    "for i in range(2008,2017):\n",
    "    temp[str(i)] = np.percentile(data[data['year']==str(i)]['up_votes'],95)\n",
    "\n",
    "# Mark hot articles\n",
    "data['label']=0\n",
    "for i in data.index:\n",
    "    if data.at[i,'up_votes'] >= temp[data.at[i,'year']]:\n",
    "        data.at[i,'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of hot articles:  25495\n",
      "# of non-hot articles:  483741\n"
     ]
    }
   ],
   "source": [
    "print('# of hot articles: ', len(data[data['label']==1]))\n",
    "print('# of non-hot articles: ', len(data[data['label']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the reviews (tokenizing, lemmatization, removing stopwords)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(titles):\n",
    "    filtered_titles = []\n",
    "    for title in titles:\n",
    "        title = title.lower()\n",
    "        token_list = word_tokenize(title) # Tokenize\n",
    "        filtered_token = [t for t in token_list if not t in stop_words] # Remove stopwords\n",
    "        for i in range(len(filtered_token)):\n",
    "            filtered_token[i] = lemmatizer.lemmatize(filtered_token[i]).strip(string.punctuation) # Lemmatization\n",
    "        filtered_titles.append(\" \".join(filtered_token))\n",
    "    return filtered_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF weighted word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "filtered_corpus = preprocessing(data[\"title\"])\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df = 0.4, max_features = 2000) # only use first 2000 features because of \n",
    "                                                                # computatioal complexity later on\n",
    "\n",
    "# vectorize the corpus\n",
    "vector = vectorizer.fit_transform(filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbas</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abe</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abu</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>yemeni</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zika</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbas  abbott  abducted  abe  able  abortion  abroad  abu  abuse  accept  \\\n",
       "0    0.0     0.0       0.0  0.0   0.0       0.0     0.0  0.0    0.0     0.0   \n",
       "1    0.0     0.0       0.0  0.0   0.0       0.0     0.0  0.0    0.0     0.0   \n",
       "2    0.0     0.0       0.0  0.0   0.0       0.0     0.0  0.0    0.0     0.0   \n",
       "3    0.0     0.0       0.0  0.0   0.0       0.0     0.0  0.0    0.0     0.0   \n",
       "4    0.0     0.0       0.0  0.0   0.0       0.0     0.0  0.0    0.0     0.0   \n",
       "\n",
       "   ...   yemeni  yet  york  young  youth  youtube  zealand  zika  zimbabwe  \\\n",
       "0  ...      0.0  0.0   0.0    0.0    0.0      0.0      0.0   0.0       0.0   \n",
       "1  ...      0.0  0.0   0.0    0.0    0.0      0.0      0.0   0.0       0.0   \n",
       "2  ...      0.0  0.0   0.0    0.0    0.0      0.0      0.0   0.0       0.0   \n",
       "3  ...      0.0  0.0   0.0    0.0    0.0      0.0      0.0   0.0       0.0   \n",
       "4  ...      0.0  0.0   0.0    0.0    0.0      0.0      0.0   0.0       0.0   \n",
       "\n",
       "   zone  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF matrix\n",
    "tfidf_matrix = pd.DataFrame(vector.toarray(), columns = vectorizer.get_feature_names())\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings for each word in the column index of TF-IDF matrix\n",
    "word2vec = [np.array(nlp(i).vector) for i in tfidf_matrix.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.912060</td>\n",
       "      <td>0.486792</td>\n",
       "      <td>0.476928</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0.054770</td>\n",
       "      <td>-0.870862</td>\n",
       "      <td>-0.268372</td>\n",
       "      <td>0.243633</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>3.758917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147540</td>\n",
       "      <td>-0.250236</td>\n",
       "      <td>-0.509609</td>\n",
       "      <td>0.120965</td>\n",
       "      <td>0.368058</td>\n",
       "      <td>0.258011</td>\n",
       "      <td>-0.647812</td>\n",
       "      <td>-0.213497</td>\n",
       "      <td>0.221647</td>\n",
       "      <td>0.039148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.324209</td>\n",
       "      <td>-0.390879</td>\n",
       "      <td>-0.141281</td>\n",
       "      <td>0.468408</td>\n",
       "      <td>0.106328</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>-0.485883</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>0.092061</td>\n",
       "      <td>3.285786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568110</td>\n",
       "      <td>0.480141</td>\n",
       "      <td>0.255341</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>-0.005795</td>\n",
       "      <td>-0.604799</td>\n",
       "      <td>-0.348221</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>-0.195351</td>\n",
       "      <td>-0.358770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.392182</td>\n",
       "      <td>0.212705</td>\n",
       "      <td>0.292572</td>\n",
       "      <td>-0.265595</td>\n",
       "      <td>0.723275</td>\n",
       "      <td>-0.399778</td>\n",
       "      <td>-0.584884</td>\n",
       "      <td>0.070501</td>\n",
       "      <td>-0.410889</td>\n",
       "      <td>2.268124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122901</td>\n",
       "      <td>0.364871</td>\n",
       "      <td>-0.286764</td>\n",
       "      <td>-0.455900</td>\n",
       "      <td>0.556184</td>\n",
       "      <td>-0.654148</td>\n",
       "      <td>-0.201398</td>\n",
       "      <td>0.354193</td>\n",
       "      <td>-0.320886</td>\n",
       "      <td>0.658890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.495490</td>\n",
       "      <td>0.646893</td>\n",
       "      <td>-0.114675</td>\n",
       "      <td>-0.209844</td>\n",
       "      <td>-0.494770</td>\n",
       "      <td>-0.815250</td>\n",
       "      <td>-0.022099</td>\n",
       "      <td>-0.126436</td>\n",
       "      <td>0.217735</td>\n",
       "      <td>6.272498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395701</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.125113</td>\n",
       "      <td>-0.427662</td>\n",
       "      <td>0.136894</td>\n",
       "      <td>-0.184926</td>\n",
       "      <td>-0.489197</td>\n",
       "      <td>-0.181203</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.072146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.521825</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>0.591420</td>\n",
       "      <td>0.060628</td>\n",
       "      <td>0.589623</td>\n",
       "      <td>0.026628</td>\n",
       "      <td>-0.254125</td>\n",
       "      <td>0.444144</td>\n",
       "      <td>-0.203941</td>\n",
       "      <td>4.084317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188162</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.389346</td>\n",
       "      <td>-0.072245</td>\n",
       "      <td>-0.124132</td>\n",
       "      <td>0.184864</td>\n",
       "      <td>0.015786</td>\n",
       "      <td>0.147740</td>\n",
       "      <td>-0.223388</td>\n",
       "      <td>0.561387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.912060  0.486792  0.476928  0.289893  0.054770 -0.870862 -0.268372   \n",
       "1 -0.324209 -0.390879 -0.141281  0.468408  0.106328  0.084631 -0.485883   \n",
       "2 -0.392182  0.212705  0.292572 -0.265595  0.723275 -0.399778 -0.584884   \n",
       "3 -0.495490  0.646893 -0.114675 -0.209844 -0.494770 -0.815250 -0.022099   \n",
       "4 -0.521825  0.040879  0.591420  0.060628  0.589623  0.026628 -0.254125   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.243633  0.638600  3.758917    ...     0.147540 -0.250236 -0.509609   \n",
       "1  0.411318  0.092061  3.285786    ...     0.568110  0.480141  0.255341   \n",
       "2  0.070501 -0.410889  2.268124    ...     0.122901  0.364871 -0.286764   \n",
       "3 -0.126436  0.217735  6.272498    ...    -0.395701  0.316228 -0.125113   \n",
       "4  0.444144 -0.203941  4.084317    ...    -0.188162  0.022798  0.389346   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.120965  0.368058  0.258011 -0.647812 -0.213497  0.221647  0.039148  \n",
       "1  0.012618 -0.005795 -0.604799 -0.348221  0.065231 -0.195351 -0.358770  \n",
       "2 -0.455900  0.556184 -0.654148 -0.201398  0.354193 -0.320886  0.658890  \n",
       "3 -0.427662  0.136894 -0.184926 -0.489197 -0.181203  0.021290  0.072146  \n",
       "4 -0.072245 -0.124132  0.184864  0.015786  0.147740 -0.223388  0.561387  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each title, use each word's TF-IDF mutliply by its word embeddings vector and sum all the word vectors\n",
    "# The result is an unweighted matrix for each title\n",
    "unweighted_matrix = pd.DataFrame(np.dot(tfidf_matrix,np.array(word2vec)))\n",
    "unweighted_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.465222</td>\n",
       "      <td>0.248302</td>\n",
       "      <td>0.243271</td>\n",
       "      <td>0.147868</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>-0.444208</td>\n",
       "      <td>-0.136891</td>\n",
       "      <td>0.124272</td>\n",
       "      <td>0.325736</td>\n",
       "      <td>1.917342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075257</td>\n",
       "      <td>-0.127640</td>\n",
       "      <td>-0.259941</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.187738</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>-0.330435</td>\n",
       "      <td>-0.108900</td>\n",
       "      <td>0.113058</td>\n",
       "      <td>0.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.189500</td>\n",
       "      <td>-0.228469</td>\n",
       "      <td>-0.082579</td>\n",
       "      <td>0.273784</td>\n",
       "      <td>0.062149</td>\n",
       "      <td>0.049467</td>\n",
       "      <td>-0.283999</td>\n",
       "      <td>0.240415</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>1.920541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332060</td>\n",
       "      <td>0.280642</td>\n",
       "      <td>0.149247</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>-0.003387</td>\n",
       "      <td>-0.353505</td>\n",
       "      <td>-0.203535</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>-0.114182</td>\n",
       "      <td>-0.209701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.197132</td>\n",
       "      <td>0.106917</td>\n",
       "      <td>0.147062</td>\n",
       "      <td>-0.133502</td>\n",
       "      <td>0.363557</td>\n",
       "      <td>-0.200950</td>\n",
       "      <td>-0.293994</td>\n",
       "      <td>0.035438</td>\n",
       "      <td>-0.206535</td>\n",
       "      <td>1.140080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061777</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>-0.144143</td>\n",
       "      <td>-0.229160</td>\n",
       "      <td>0.279568</td>\n",
       "      <td>-0.328809</td>\n",
       "      <td>-0.101234</td>\n",
       "      <td>0.178036</td>\n",
       "      <td>-0.161294</td>\n",
       "      <td>0.331193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.222323</td>\n",
       "      <td>0.290256</td>\n",
       "      <td>-0.051454</td>\n",
       "      <td>-0.094156</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>-0.365797</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>-0.056731</td>\n",
       "      <td>0.097696</td>\n",
       "      <td>2.814425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177548</td>\n",
       "      <td>0.141889</td>\n",
       "      <td>-0.056137</td>\n",
       "      <td>-0.191889</td>\n",
       "      <td>0.061423</td>\n",
       "      <td>-0.082975</td>\n",
       "      <td>-0.219499</td>\n",
       "      <td>-0.081305</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.032371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.301983</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>0.342258</td>\n",
       "      <td>0.035086</td>\n",
       "      <td>0.341218</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>-0.147064</td>\n",
       "      <td>0.257029</td>\n",
       "      <td>-0.118022</td>\n",
       "      <td>2.363621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108891</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.225317</td>\n",
       "      <td>-0.041809</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.106982</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>-0.129276</td>\n",
       "      <td>0.324879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.465222  0.248302  0.243271  0.147868  0.027937 -0.444208 -0.136891   \n",
       "1 -0.189500 -0.228469 -0.082579  0.273784  0.062149  0.049467 -0.283999   \n",
       "2 -0.197132  0.106917  0.147062 -0.133502  0.363557 -0.200950 -0.293994   \n",
       "3 -0.222323  0.290256 -0.051454 -0.094156 -0.222000 -0.365797 -0.009915   \n",
       "4 -0.301983  0.023657  0.342258  0.035086  0.341218  0.015410 -0.147064   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.124272  0.325736  1.917342    ...     0.075257 -0.127640 -0.259941   \n",
       "1  0.240415  0.053810  1.920541    ...     0.332060  0.280642  0.149247   \n",
       "2  0.035438 -0.206535  1.140080    ...     0.061777  0.183404 -0.144143   \n",
       "3 -0.056731  0.097696  2.814425    ...    -0.177548  0.141889 -0.056137   \n",
       "4  0.257029 -0.118022  2.363621    ...    -0.108891  0.013193  0.225317   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.061702  0.187738  0.131606 -0.330435 -0.108900  0.113058  0.019968  \n",
       "1  0.007375 -0.003387 -0.353505 -0.203535  0.038127 -0.114182 -0.209701  \n",
       "2 -0.229160  0.279568 -0.328809 -0.101234  0.178036 -0.161294  0.331193  \n",
       "3 -0.191889  0.061423 -0.082975 -0.219499 -0.081305  0.009553  0.032371  \n",
       "4 -0.041809 -0.071836  0.106982  0.009136  0.085498 -0.129276  0.324879  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each title, use unweighted matrix divided by the sum of that title's TF-IDF to get weighted word2vec matrix\n",
    "# The result is our final word2vec matrix\n",
    "final_w2v = unweighted_matrix.div(tfidf_matrix.sum(axis=1), axis=0)\n",
    "final_w2v = final_w2v.fillna(0)\n",
    "final_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509236, 301)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add label to final_w2v\n",
    "final_w2v[\"label\"] = np.array(data[\"label\"])\n",
    "final_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split train(70%) and test(30%)\n",
    "reddit_train, reddit_test, y_train, y_test = train_test_split(\n",
    "    final_w2v.iloc[:,:-1],\n",
    "    final_w2v[\"label\"],\n",
    "    test_size=0.3,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Variable - hot_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### author = 1 if he/she had writen a hot article (in train dataset)\n",
    "author=set()\n",
    "for i in final_w2v.index:\n",
    "    if final_w2v.at[i,'label']==1:\n",
    "        author.add(data.at[i,'author'])\n",
    "        \n",
    "reddit_train['hot_author']=0\n",
    "reddit_test['hot_author']=0\n",
    "for i in reddit_train.index:\n",
    "    if data.at[i,'author'] in author:\n",
    "        reddit_train.at[i,'hot_author']=1\n",
    "for i in reddit_test.index:\n",
    "    if data.at[i,'author'] in author:\n",
    "        reddit_test.at[i,'hot_author']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append w2v and author variable together\n",
    "final_variables = pd.DataFrame(np.concatenate((reddit_train,reddit_test)), columns = reddit_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509236, 141)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep 90% of original information\n",
    "pca = PCA(n_components = 0.9)\n",
    "pca_features = pca.fit_transform(np.array(final_variables))\n",
    "pca_df = pd.DataFrame(pca_features)\n",
    "pca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test independent variables\n",
    "train_row = len(reddit_train)\n",
    "test_row = len(reddit_test)\n",
    "X_train = pca_df[:int(train_row)]\n",
    "X_test = pca_df[-int(test_row):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegressionCV(multi_class=\"ovr\",fit_intercept=True,Cs=np.logspace(-2,2,20),cv=2,penalty=\"l2\",solver=\"lbfgs\",tol=0.01)\n",
    "re = lr.fit(X_train,y_train)\n",
    "train_prob=re.predict_proba(X_train)\n",
    "test_prob=re.predict_proba(X_test)\n",
    "train_df = pd.DataFrame(train_prob,index=y_train.index,columns = ['prob', 'y'])\n",
    "train_df['y']=y_train\n",
    "test_df = pd.DataFrame(test_prob,index=y_test.index,columns = ['prob', 'y'])\n",
    "test_df['y']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FDR@5% of Logistic regression: 16.99%\n"
     ]
    }
   ],
   "source": [
    "# Get the train FDR@5% of Logistic regression\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(train_df.index))\n",
    "for i in train_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=train_df.loc[i,'y']\n",
    "# train\n",
    "print('train FDR@5% of Logistic regression:', '{:.2%}'.format(k/sum(train_df['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test FDR@5% of Logistic regression: 17.05%\n"
     ]
    }
   ],
   "source": [
    "# Get the test FDR@5% of Logistic regression\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(test_df.index))\n",
    "for i in test_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=test_df.loc[i,'y']\n",
    "# test\n",
    "print('test FDR@5% of Logistic regression:', '{:.2%}'.format(k/sum(test_df['y'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT\n",
    "gbm = GradientBoostingClassifier(random_state=10)\n",
    "gbm.fit(X_train,y_train)\n",
    "train_prob=gbm.predict_proba(X_train)\n",
    "test_prob=gbm.predict_proba(X_test)\n",
    "train_df = pd.DataFrame(train_prob,index=y_train.index,columns = ['prob', 'y'])\n",
    "train_df['y']=y_train\n",
    "test_df = pd.DataFrame(test_prob,index=y_test.index,columns = ['prob', 'y'])\n",
    "test_df['y']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FDR@5% of GBDT: 20.83%\n"
     ]
    }
   ],
   "source": [
    "# Get the train FDR@5% of Gradient Boost Decision Tree\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(train_df.index))\n",
    "for i in train_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=train_df.loc[i,'y']\n",
    "# train\n",
    "print('train FDR@5% of GBDT:', '{:.2%}'.format(k/sum(train_df['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test FDR@5% of GBDT: 18.45%\n"
     ]
    }
   ],
   "source": [
    "# Get the test FDR@5% of Gradient Boost Decision Tree\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(test_df.index))\n",
    "for i in test_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=test_df.loc[i,'y']\n",
    "# test\n",
    "print('test FDR@5% of GBDT:', '{:.2%}'.format(k/sum(test_df['y'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(21,6), random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "train_prob=nn.predict_proba(X_train)\n",
    "test_prob=nn.predict_proba(X_test)\n",
    "train_df = pd.DataFrame(train_prob,index=y_train.index,columns = ['prob', 'y'])\n",
    "train_df['y']=y_train\n",
    "test_df = pd.DataFrame(test_prob,index=y_test.index,columns = ['prob', 'y'])\n",
    "test_df['y']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FDR@5% of Neural Network: 27.93%\n"
     ]
    }
   ],
   "source": [
    "# Get the train FDR@5% of Neural Network\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(train_df.index))\n",
    "for i in train_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=train_df.loc[i,'y']\n",
    "# train\n",
    "print('train FDR@5% of Neural Network:', '{:.2%}'.format(k/sum(train_df['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test FDR@5% of Neural Network: 19.73%\n"
     ]
    }
   ],
   "source": [
    "# Get the test FDR@5% of Neural Network\n",
    "k=0\n",
    "cur=0\n",
    "num=int(0.05*len(test_df.index))\n",
    "for i in test_df.sort_values(by='prob').index:\n",
    "    if cur<num:\n",
    "        cur+=1\n",
    "        k+=test_df.loc[i,'y']\n",
    "# test\n",
    "print('test FDR@5% of Neural Network:', '{:.2%}'.format(k/sum(test_df['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fdr_graph=[]\n",
    "k=0\n",
    "cur=0\n",
    "data_size=len(test_df.index)\n",
    "for i in test_df.sort_values(by='prob').index:\n",
    "    cur+=1\n",
    "    k+=test_df.loc[i,'y']\n",
    "    fdr_graph.append((k/sum(test_df['y']),cur/data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_graph_df=pd.DataFrame(fdr_graph,columns=['% Hot Posts Caught','% Total Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Hot Posts Caught</th>\n",
       "      <th>% Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % Hot Posts Caught  % Total Population\n",
       "0            0.000000            0.000007\n",
       "1            0.000133            0.000013\n",
       "2            0.000133            0.000020\n",
       "3            0.000133            0.000026\n",
       "4            0.000133            0.000033"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr_graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0,'-20.00%'),\n",
       " Text(0,0,'0.00%'),\n",
       " Text(0,0,'20.00%'),\n",
       " Text(0,0,'40.00%'),\n",
       " Text(0,0,'60.00%'),\n",
       " Text(0,0,'80.00%'),\n",
       " Text(0,0,'100.00%'),\n",
       " Text(0,0,'120.00%')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=sns.lineplot(x='% Total Population',y='% Hot Posts Caught',\n",
    "            data=fdr_graph_df)\n",
    "vals_y = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals_y])\n",
    "vals_x = ax.get_xticks()\n",
    "ax.set_xticklabels(['{:,.2%}'.format(x) for x in vals_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
